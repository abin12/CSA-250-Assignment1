# -*- coding: utf-8 -*-
"""Train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/115OrctanLkrymOmOjNg-RDkEuXjjEpSz
"""

from platform import python_version
import tensorflow as tf
from tensorflow import keras
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Activation,Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback,EarlyStopping
import random
print("Python Version :"+python_version())
print("Tensorflow Version :"+tf.version.VERSION)

def fizzbuzz1(i):     #software 1
  a=i%3;
  b=i%5;
  if((a+b)==0):
    return("fizzbuzz")
  elif(a==0):
    return("fizz")
  elif(b==0):
    return("buzz")
  else: 
    return(str(i))
def fizzbuzz2(i):     #software 2
  a=i%3;
  b=i%5;
  if((a+b)==0):
    return [0,0,0,1]
  elif(a==0):
    return [0,1,0,0]
  elif(b==0):
    return [0,0,1,0]
  else: 
    return [1,0,0,0]
print(tf.version.VERSION)

def dec2bin10(i):
  binrep=np.zeros(10)
  j=9;
  while(i!=0):
    binrep[j]=i%2;
    i=int(i/2);
    j=j-1;
  return binrep

test_num=np.arange(1,101,1)
test_data=[]
test_label=[]
train_num=np.arange(101,1001,1)
train_data=[]
train_label=[]
for i in range(101,1001):
  train_data.append(dec2bin10(i));
  train_label.append(fizzbuzz2(i));
for i in range(1,101):
  test_data.append(dec2bin10(i));
  test_label.append(fizzbuzz2(i));
    
train_data=np.array(train_data);
test_data=np.array(test_data);
train_label=np.array(train_label);
test_label=np.array(test_label);

num_digits = 10 # binary encode numbers
nb_classes = 4 # 4 classes : number/fizz/buzz/fizzbuzz
batch_size = 128

class EarlyStopping(Callback):
    def __init__(self, monitor='accuracy', value=1.0, verbose=0):
        super(Callback, self).__init__()
        self.monitor = monitor
        self.value = value
        self.verbose = verbose

    def on_epoch_end(self, epoch, logs={}):
        current = logs.get(self.monitor)
        if current is None:
            print ("Early stopping requires %s available!" % self.monitor, RuntimeWarning)

        if current < self.value:
            if self.verbose > 0:
                print("Epoch %05d: early stopping THR" % epoch)
            self.model.stop_training = True


def fizz_buzz_pred(i, pred): #output for each prediction
    return [str(i), "fizz", "buzz", "fizzbuzz"][pred.argmax()]

combined = list(zip(train_data, train_label));
random.shuffle(combined)
train_data, train_label = zip(*combined)
train_data=np.array(train_data)
train_label=np.array(train_label)

#Our Model
tf.keras.backend.clear_session() 
model = Sequential()
model.add(Dense(32, input_shape=(num_digits,)))
model.add(Activation('relu'))
model.add(Dense(4))
model.add(Activation('softmax'))
# cross entropy is used as loss function

model.compile(loss='categorical_crossentropy',optimizer=Adam())

callbacks = [EarlyStopping(monitor='loss',verbose=1)]

model.fit(train_data,train_label,nb_epoch=1000,batch_size=batch_size)
model.save('my_model.h5')

model = tf.keras.models.load_model('my_model2.h5')
errors=0;
correct=0;
for i in range(1,101):
    x = dec2bin10(i)
    y = model.predict(np.array(x).reshape(-1,10))
    
    if fizz_buzz_pred(i,y) == fizzbuzz1(i):
        correct = correct + 1
    else:
        print(str(i)+fizz_buzz_pred(i,y))
        errors = errors + 1

print ("Errors :" , errors, " Correct :", correct)

x = dec2bin10(93)
model.predict(np.array(x).reshape(-1,10))

combined = list(zip(train_data, train_label));
random.shuffle(combined)
train_data, train_label = zip(*combined)
train_data=np.array(train_data)
train_label=np.array(train_label)
model = tf.keras.models.load_model('my_model.h5')
model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.005))
model.fit(train_data,train_label,nb_epoch=1000,batch_size=batch_size,verbose=1)#,callbacks=callbacks)

errors = 0
correct = 0
model.save('my_model.h5')

x.shape

model.summary()

model.save('my_model2.h5')
from google.colab import files
files.download("my_model2.h5")